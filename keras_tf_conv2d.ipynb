{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll check and build equivalence between tf and keras using simple examples.\n",
    "Let's first build a conv2d block in tf (and a conv2d block in keras) and compare between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# load weights from https://dl.dropboxusercontent.com/u/50333326/vgg16.npy\n",
    "path = '/home/ariel/DL/tensorflow/tutorials/'\n",
    "vgg16_npy_path = os.path.join(path, 'vgg16.npy')            \n",
    "data_dict = np.load(vgg16_npy_path, encoding='latin1').item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys in layers =  ['conv5_1', 'fc6', 'conv5_3', 'fc7', 'fc8', 'conv5_2', 'conv4_1', 'conv4_2', 'conv4_3', 'conv3_3', 'conv3_2', 'conv3_1', 'conv1_1', 'conv1_2', 'conv2_2', 'conv2_1'] \n",
      "\n",
      "weights shape in conv1_1 (3, 3, 3, 64) \n",
      "\n",
      "bias shape in conv1_1 (64,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print keys in dictionary - \n",
    "# here it prints all the layers names in the VGG net\n",
    "name = 'conv1_1'\n",
    "print 'keys in layers = ', data_dict.keys(), '\\n'\n",
    "# tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "print 'weights shape in conv1_1', data_dict[name][0].shape, '\\n'\n",
    "print 'bias shape in conv1_1', data_dict[name][1].shape, '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build a convolution block in tf. A convoution block is built out of:\n",
    "1. a 2d convolution\n",
    "2. an added bias\n",
    "3. a relu module\n",
    "All the code bellow is taken from:\n",
    "https://github.com/MarvinTeichmann/tensorflow-fcn/blob/master/fcn16_vgg.py\n",
    "\n",
    "In the code bellow the function tf.get_variable() is used to get/create a variable instead \n",
    "of a direct call to tf.Variable(). It uses an initalizer - 3 kind:\n",
    "1. tf.constant_initializer(value) initializes everything to the provided value\n",
    "2. tf.random_uniform_initializer(a, b) initializes uniformly from [a, b]\n",
    "3. tf.random_normal_initializer(mean, stddev) initializes from the normal distribution with the given mean and standard deviation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _bias_reshape(bweight, num_orig, num_new):\n",
    "    \"\"\" Build bias weights for filter produces with `_summary_reshape`\n",
    "    \"\"\"\n",
    "    n_averaged_elements = num_orig//num_new\n",
    "    avg_bweight = np.zeros(num_new)\n",
    "    for i in range(0, num_orig, n_averaged_elements):\n",
    "        start_idx = i\n",
    "        end_idx = start_idx + n_averaged_elements\n",
    "        avg_idx = start_idx//n_averaged_elements\n",
    "        if avg_idx == num_new:\n",
    "            break\n",
    "        avg_bweight[avg_idx] = np.mean(bweight[start_idx:end_idx])\n",
    "    return avg_bweight\n",
    "\n",
    "# need to understand this! Only for fc8, the bias is recalculated!\n",
    "def get_bias(name, num_classes=None):\n",
    "    bias_wights = data_dict[name][1]\n",
    "    shape = data_dict[name][1].shape\n",
    "    if name == 'fc8':\n",
    "        bias_wights = _bias_reshape(bias_wights, shape[0], num_classes)\n",
    "        shape = [num_classes]\n",
    "    init = tf.constant_initializer(value=bias_wights, dtype=tf.float32)\n",
    "    return tf.get_variable(name=\"biases\", initializer=init, shape=shape)\n",
    "\n",
    "def get_conv_filter(name):\n",
    "    with tf.variable_scope(\"C\"):\n",
    "        init = tf.constant_initializer(value=data_dict[name][0], dtype=tf.float32)\n",
    "        shape = data_dict[name][0].shape\n",
    "        print('Layer name: %s' % name)\n",
    "        print('Layer shape: %s' % str(shape))\n",
    "        var = tf.get_variable(name=\"filter\", initializer=init, shape=shape)\n",
    "#     if not tf.get_variable_scope().reuse:\n",
    "#         weight_decay = tf.multiply(tf.nn.l2_loss(var), self.wd,\n",
    "#                                    name='weight_loss')\n",
    "#         tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES,\n",
    "#                              weight_decay)\n",
    "    return var\n",
    "\n",
    "def get_weights(name):\n",
    "    init = tf.constant_initializer(value=data_dict[name][0], dtype=tf.float32)\n",
    "    weights = tf.get_variable(name=\"weights\", initializer=init, shape=data_dict[name][0].shape)\n",
    "    return weights\n",
    "\n",
    "def get_biases(name):\n",
    "    init = tf.constant_initializer(value=data_dict[name][1], dtype=tf.float32)\n",
    "    biases = tf.get_variable(name=\"biases\", initializer=init, shape=data_dict[name][1].shape)\n",
    "    return biases\n",
    "\n",
    "def _conv_layer(bottom, name):\n",
    "    with tf.variable_scope(name):# as scope:\n",
    "        # get filter weights\n",
    "        weights = get_weights(name)\n",
    "       \n",
    "        # get filter biases\n",
    "        biases = get_biases(name)\n",
    "\n",
    "        # convolve: weights * bottom\n",
    "        conv = tf.nn.conv2d(bottom, weights, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # add biases: weights * bottom + biases\n",
    "        conv_biases = tf.nn.bias_add(conv, biases)\n",
    "\n",
    "        # relu: relu(weights * bottom + biases)\n",
    "        conv_biases_relu = tf.nn.relu(conv_biases)\n",
    "\n",
    "        return conv_biases_relu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the _conv_layer on a simple image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.05118346,  0.07285573,  0.07526198, ...,  1.41887295,\n",
       "           0.50928986,  0.50768656],\n",
       "         [ 0.97429979,  0.07416046,  0.00820402, ...,  1.48566544,\n",
       "           0.30226624,  0.37049884],\n",
       "         [ 0.97427028,  0.07416278,  0.00821107, ...,  1.48564315,\n",
       "           0.30229396,  0.37051302],\n",
       "         ..., \n",
       "         [ 0.96782184,  0.07467214,  0.00975351, ...,  1.48075283,\n",
       "           0.30836394,  0.37361217],\n",
       "         [ 0.96779239,  0.07467446,  0.00976057, ...,  1.48073053,\n",
       "           0.30839169,  0.37362629],\n",
       "         [ 0.72999299,  0.08021346,  0.        , ...,  1.40367281,\n",
       "           0.17518124,  0.21808174]],\n",
       "\n",
       "        [[ 0.94112337,  0.06718749,  0.10576713, ...,  1.48901117,\n",
       "           0.72521597,  0.62522233],\n",
       "         [ 0.72031772,  0.07191091,  0.02346974, ...,  1.58839536,\n",
       "           0.53925383,  0.48371553],\n",
       "         [ 0.7203179 ,  0.07191356,  0.02347515, ...,  1.58836007,\n",
       "           0.53925395,  0.48371652],\n",
       "         ..., \n",
       "         [ 0.72034842,  0.0724954 ,  0.02465892, ...,  1.58064818,\n",
       "           0.53927898,  0.483933  ],\n",
       "         [ 0.7203486 ,  0.07249807,  0.02466434, ...,  1.5806129 ,\n",
       "           0.53927904,  0.48393399],\n",
       "         [ 0.46898404,  0.08014192,  0.        , ...,  1.47028279,\n",
       "           0.27879417,  0.23460674]],\n",
       "\n",
       "        [[ 0.93519783,  0.06791046,  0.10471775, ...,  1.48386312,\n",
       "           0.72004682,  0.62153804],\n",
       "         [ 0.72034907,  0.07250603,  0.02468056, ...,  1.58050728,\n",
       "           0.5392794 ,  0.48393697],\n",
       "         [ 0.72034913,  0.07250869,  0.02468595, ...,  1.58047211,\n",
       "           0.53927952,  0.48393792],\n",
       "         ..., \n",
       "         [ 0.72037977,  0.07309054,  0.02586973, ...,  1.57276011,\n",
       "           0.53930449,  0.48415437],\n",
       "         [ 0.72037995,  0.07309318,  0.02587515, ...,  1.57272482,\n",
       "           0.53930461,  0.48415539],\n",
       "         [ 0.47620916,  0.08052082,  0.        , ...,  1.46552134,\n",
       "           0.28612441,  0.24187347]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.        ,  0.22624016,  0.        , ...,  0.35643041,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.72720659,  0.20283857,  0.28984696, ...,  0.        ,\n",
       "           0.54487795,  0.53242338],\n",
       "         [ 0.72720683,  0.20284121,  0.28985238, ...,  0.        ,\n",
       "           0.54487801,  0.53242427],\n",
       "         ..., \n",
       "         [ 0.72723722,  0.20342305,  0.29103619, ...,  0.        ,\n",
       "           0.54490292,  0.53264081],\n",
       "         [ 0.7272374 ,  0.20342569,  0.29104158, ...,  0.        ,\n",
       "           0.5449031 ,  0.53264177],\n",
       "         [ 2.05849504,  0.16349977,  0.79002273, ...,  0.42276365,\n",
       "           1.89144933,  1.83329093]],\n",
       "\n",
       "        [[ 0.        ,  0.2269631 ,  0.        , ...,  0.35128236,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.72723818,  0.20343369,  0.29105783, ...,  0.        ,\n",
       "           0.54490358,  0.53264481],\n",
       "         [ 0.72723824,  0.20343634,  0.29106325, ...,  0.        ,\n",
       "           0.54490358,  0.53264576],\n",
       "         ..., \n",
       "         [ 0.72726846,  0.20401818,  0.29224703, ...,  0.        ,\n",
       "           0.54492867,  0.53286225],\n",
       "         [ 0.72726864,  0.20402084,  0.29225239, ...,  0.        ,\n",
       "           0.54492867,  0.53286314],\n",
       "         [ 2.06572008,  0.16387863,  0.7939353 , ...,  0.41800219,\n",
       "           1.89877963,  1.84055769]],\n",
       "\n",
       "        [[ 0.69158113,  0.18588914,  0.04570306, ...,  0.71796989,\n",
       "           0.        ,  0.12463945],\n",
       "         [ 1.87671089,  0.16472188,  0.41292545, ...,  0.40720427,\n",
       "           0.        ,  0.73396349],\n",
       "         [ 1.87673855,  0.16472363,  0.41293374, ...,  0.40718263,\n",
       "           0.        ,  0.73396927],\n",
       "         ..., \n",
       "         [ 1.88278902,  0.16509953,  0.41474947, ...,  0.40245575,\n",
       "           0.        ,  0.73523885],\n",
       "         [ 1.88281667,  0.16510129,  0.41475773, ...,  0.40243411,\n",
       "           0.        ,  0.73524463],\n",
       "         [ 2.59829926,  0.13679579,  0.72483182, ...,  0.7709496 ,\n",
       "           1.04815054,  1.61918104]]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this command clean all nodes in the graph + variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# load an image\n",
    "IMAGE_SIZE = 224\n",
    "img_shape = (1, IMAGE_SIZE, IMAGE_SIZE, 3) # tf format (N,H,W,C)\n",
    "img = np.linspace(-0.1, 0.5, num=np.prod(img_shape)).reshape(img_shape)\n",
    "tf_img = tf.Variable(img, name=\"img\", dtype=tf.float32)\n",
    "\n",
    "_conv1_1 = _conv_layer(tf_img, 'conv1_1')\n",
    "# _conv1_2 = _conv_layer(_conv1_1, 'conv1_2')\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "sess.run(_conv1_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, let's do the same with keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tensorflow.python.framework.ops.Operation object at 0x7f780754f410> cannot be interpreted as a Tensor. (Operation name: \"init_1\"\nop: \"NoOp\"\ninput: \"^img/Assign\"\ninput: \"^conv1_1/weights/Assign\"\ninput: \"^conv1_1/biases/Assign\"\ninput: \"^convolution2d_11_W/Assign\"\ninput: \"^convolution2d_11_b/Assign\"\n is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a6b3eda0d1b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                         \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# shape of input image = ROWS x COLS x CHANNELS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                         \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                         weights=[weight, bias])) # initial weights\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# add a conv2d layer to this model with initial weights and biases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Keras-1.1.1-py2.7.egg/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0minput_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_input_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Keras-1.1.1-py2.7.egg/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mcreate_input_layer\u001b[0;34m(self, batch_input_shape, input_dtype, name)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Keras-1.1.1-py2.7.egg/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    491\u001b[0m                                      '`layer.build(batch_input_shape)`')\n\u001b[1;32m    492\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Keras-1.1.1-py2.7.egg/keras/layers/convolutional.pyc\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_weights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Keras-1.1.1-py2.7.egg/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m         \u001b[0mparam_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Keras-1.1.1-py2.7.egg/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(xs)\u001b[0m\n\u001b[1;32m    997\u001b[0m     '''\n\u001b[1;32m    998\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Keras-1.1.1-py2.7.egg/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/Keras-1.1.1-py2.7.egg/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m()\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muninitialized_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m     \u001b[0mfetch_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \"\"\"\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 225\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    226\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument <tensorflow.python.framework.ops.Operation object at 0x7f780754f410> cannot be interpreted as a Tensor. (Operation name: \"init_1\"\nop: \"NoOp\"\ninput: \"^img/Assign\"\ninput: \"^conv1_1/weights/Assign\"\ninput: \"^conv1_1/biases/Assign\"\ninput: \"^convolution2d_11_W/Assign\"\ninput: \"^convolution2d_11_b/Assign\"\n is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "# build a simple model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "\n",
    "model = Sequential()\n",
    "nb_filters_out = data_dict[name][0].shape[3]\n",
    "nb_rows = data_dict[name][0].shape[0]\n",
    "nb_cols = data_dict[name][0].shape[1]\n",
    "nb_channels = data_dict[name][0].shape[2]\n",
    "weight = data_dict[name][0]\n",
    "bias = data_dict[name][1]\n",
    "    \n",
    "model.add(Convolution2D(nb_filters_out, # number of output filters\n",
    "                        nb_rows,        # number of rows in the input kernel   \n",
    "                        nb_cols,        # number of cols in the input kernel   \n",
    "                        border_mode='same', \n",
    "                        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), # shape of input image = ROWS x COLS x CHANNELS \n",
    "                        activation='relu', # activation\n",
    "                        weights=[weight, bias])) # initial weights\n",
    "\n",
    "# add a conv2d layer to this model with initial weights and biases\n",
    "\n",
    "# run on a simple image\n",
    "model.predict(img, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
