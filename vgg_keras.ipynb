{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement VGG using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys in layers =  ['conv5_1', 'fc6', 'conv5_3', 'fc7', 'fc8', 'conv5_2', 'conv4_1', 'conv4_2', 'conv4_3', 'conv3_3', 'conv3_2', 'conv3_1', 'conv1_1', 'conv1_2', 'conv2_2', 'conv2_1'] \n",
      "\n",
      "weights shape in conv1_1 (3, 3, 3, 64) \n",
      "\n",
      "bias shape in conv1_1 (64,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# load weights from https://dl.dropboxusercontent.com/u/50333326/vgg16.npy\n",
    "path = '/home/ariel/DL/tensorflow/tutorials/'\n",
    "vgg16_npy_path = os.path.join(path, 'vgg16.npy')            \n",
    "data_dict = np.load(vgg16_npy_path, encoding='latin1').item()\n",
    "\n",
    "# print keys in dictionary - \n",
    "# here it prints all the layers names in the VGG net\n",
    "name = 'conv1_1'\n",
    "print 'keys in layers = ', data_dict.keys(), '\\n'\n",
    "# tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "print 'weights shape in conv1_1', data_dict[name][0].shape, '\\n'\n",
    "print 'bias shape in conv1_1', data_dict[name][1].shape, '\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** the network **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_data(name):\n",
    "    nb_filters_out = data_dict[name][0].shape[3]\n",
    "    nb_rows = data_dict[name][0].shape[0]\n",
    "    nb_cols = data_dict[name][0].shape[1]\n",
    "    nb_channels = data_dict[name][0].shape[2]\n",
    "    weight = data_dict[name][0]\n",
    "    bias = data_dict[name][1]\n",
    "    return nb_filters_out, nb_rows, nb_cols, nb_channels, weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7, 7, 512)\n",
      "[[[[ 0.04152922  0.          0.         ...,  0.          0.76243585  0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.73776311  0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.73881972  0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.72844511  0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.79345977  0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.78591818  0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.         ...,  0.          0.67036343  0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.70792282  0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.72337979  0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.72094685  0.        ]\n",
      "   [ 0.06755218  0.          0.         ...,  0.          0.66223222  0.        ]\n",
      "   [ 0.07043768  0.          0.         ...,  0.          0.69173503  0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.         ...,  0.          0.67313582  0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.7398631   0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.74472582  0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.74327683  0.        ]\n",
      "   [ 0.0562786   0.          0.         ...,  0.          0.67947733  0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.64110082  0.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.          0.          0.         ...,  0.          0.683025    0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.71301287  0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.71626157  0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.71500897  0.        ]\n",
      "   [ 0.03658648  0.          0.         ...,  0.          0.63591945  0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.62517077  0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.         ...,  0.          0.74236947  0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.65076977  0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.66111845  0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.662561    0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.57818824  0.        ]\n",
      "   [ 0.          0.          0.         ...,  0.          0.58536279  0.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.10145122 ...,  0.          0.84740597  0.        ]\n",
      "   [ 0.          0.          0.04614043 ...,  0.          0.72118312  0.        ]\n",
      "   [ 0.          0.          0.04577801 ...,  0.          0.6965946   0.        ]\n",
      "   ..., \n",
      "   [ 0.          0.          0.0362125  ...,  0.          0.70292878  0.        ]\n",
      "   [ 0.          0.          0.01458383 ...,  0.          0.67077625  0.        ]\n",
      "   [ 0.          0.          0.06460804 ...,  0.          0.59977245  0.        ]]]]\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_27 (Convolution2D) (None, 224, 224, 64)  1792        convolution2d_input_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_28 (Convolution2D) (None, 224, 224, 64)  36928       convolution2d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_11 (MaxPooling2D)   (None, 112, 112, 64)  0           convolution2d_28[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_29 (Convolution2D) (None, 112, 112, 128) 73856       maxpooling2d_11[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_30 (Convolution2D) (None, 112, 112, 128) 147584      convolution2d_29[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_12 (MaxPooling2D)   (None, 56, 56, 128)   0           convolution2d_30[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_31 (Convolution2D) (None, 56, 56, 256)   295168      maxpooling2d_12[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_32 (Convolution2D) (None, 56, 56, 256)   590080      convolution2d_31[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_33 (Convolution2D) (None, 56, 56, 256)   590080      convolution2d_32[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_13 (MaxPooling2D)   (None, 28, 28, 256)   0           convolution2d_33[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_34 (Convolution2D) (None, 28, 28, 512)   1180160     maxpooling2d_13[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_35 (Convolution2D) (None, 28, 28, 512)   2359808     convolution2d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_36 (Convolution2D) (None, 28, 28, 512)   2359808     convolution2d_35[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_14 (MaxPooling2D)   (None, 14, 14, 512)   0           convolution2d_36[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_37 (Convolution2D) (None, 14, 14, 512)   2359808     maxpooling2d_14[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_38 (Convolution2D) (None, 14, 14, 512)   2359808     convolution2d_37[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_39 (Convolution2D) (None, 14, 14, 512)   2359808     convolution2d_38[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_15 (MaxPooling2D)   (None, 7, 7, 512)     0           convolution2d_39[0][0]           \n",
      "====================================================================================================\n",
      "Total params: 14714688\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a simple model\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "\n",
    "# load an image\n",
    "IMAGE_SIZE = 224\n",
    "img_shape = (1, IMAGE_SIZE, IMAGE_SIZE, 3) # tf format (N,H,W,C)\n",
    "img = np.linspace(-0.1, 0.5, num=np.prod(img_shape)).reshape(img_shape)\n",
    "\n",
    "# the network\n",
    "model = Sequential()\n",
    "\n",
    "nb_filters_out, nb_rows, nb_cols, nb_channels, weight, bias = extract_data('conv1_1')    \n",
    "model.add(Convolution2D(nb_filters_out, # number of output filters\n",
    "                        nb_rows,        # number of rows in the input kernel   \n",
    "                        nb_cols,        # number of cols in the input kernel   \n",
    "                        border_mode='same', \n",
    "                        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), # shape of input image = ROWS x COLS x CHANNELS \n",
    "                        activation='relu', # activation\n",
    "                        weights=[weight, bias])) # initial weights\n",
    "\n",
    "nb_filters_out, nb_rows, nb_cols, nb_channels, weight, bias = extract_data('conv1_2')    \n",
    "model.add(Convolution2D(nb_filters_out, # number of output filters\n",
    "                        nb_rows,        # number of rows in the input kernel   \n",
    "                        nb_cols,        # number of cols in the input kernel   \n",
    "                        border_mode='same', \n",
    "                        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), # shape of input image = ROWS x COLS x CHANNELS \n",
    "                        activation='relu', # activation\n",
    "                        weights=[weight, bias])) # initial weights\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='same'))\n",
    "\n",
    "nb_filters_out, nb_rows, nb_cols, nb_channels, weight, bias = extract_data('conv2_1')    \n",
    "model.add(Convolution2D(nb_filters_out, # number of output filters\n",
    "                        nb_rows,        # number of rows in the input kernel   \n",
    "                        nb_cols,        # number of cols in the input kernel   \n",
    "                        border_mode='same', \n",
    "                        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), # shape of input image = ROWS x COLS x CHANNELS \n",
    "                        activation='relu', # activation\n",
    "                        weights=[weight, bias])) # initial weights\n",
    "\n",
    "nb_filters_out, nb_rows, nb_cols, nb_channels, weight, bias = extract_data('conv2_2')    \n",
    "model.add(Convolution2D(nb_filters_out, # number of output filters\n",
    "                        nb_rows,        # number of rows in the input kernel   \n",
    "                        nb_cols,        # number of cols in the input kernel   \n",
    "                        border_mode='same', \n",
    "                        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), # shape of input image = ROWS x COLS x CHANNELS \n",
    "                        activation='relu', # activation\n",
    "                        weights=[weight, bias])) # initial weights\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='same'))\n",
    "\n",
    "nb_filters_out, nb_rows, nb_cols, nb_channels, weight, bias = extract_data('conv3_1')    \n",
    "model.add(Convolution2D(nb_filters_out, # number of output filters\n",
    "                        nb_rows,        # number of rows in the input kernel   \n",
    "                        nb_cols,        # number of cols in the input kernel   \n",
    "                        border_mode='same', \n",
    "                        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), # shape of input image = ROWS x COLS x CHANNELS \n",
    "                        activation='relu', # activation\n",
    "                        weights=[weight, bias])) # initial weights\n",
    "\n",
    "nb_filters_out, nb_rows, nb_cols, nb_channels, weight, bias = extract_data('conv3_2')    \n",
    "model.add(Convolution2D(nb_filters_out, # number of output filters\n",
    "                        nb_rows,        # number of rows in the input kernel   \n",
    "                        nb_cols,        # number of cols in the input kernel   \n",
    "                        border_mode='same', \n",
    "                        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), # shape of input image = ROWS x COLS x CHANNELS \n",
    "                        activation='relu', # activation\n",
    "                        weights=[weight, bias])) # initial weights\n",
    "\n",
    "nb_filters_out, nb_rows, nb_cols, nb_channels, weight, bias = extract_data('conv3_3')    \n",
    "model.add(Convolution2D(nb_filters_out, # number of output filters\n",
    "                        nb_rows,        # number of rows in the input kernel   \n",
    "                        nb_cols,        # number of cols in the input kernel   \n",
    "                        border_mode='same', \n",
    "                        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), # shape of input image = ROWS x COLS x CHANNELS \n",
    "                        activation='relu', # activation\n",
    "                        weights=[weight, bias])) # initial weights\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='same'))\n",
    "\n",
    "\n",
    "nb_filters_out, nb_rows, nb_cols, nb_channels, weight, bias = extract_data('conv4_1')    \n",
    "model.add(Convolution2D(nb_filters_out, # number of output filters\n",
    "                        nb_rows,        # number of rows in the input kernel   \n",
    "                        nb_cols,        # number of cols in the input kernel   \n",
    "                        border_mode='same', \n",
    "                        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), # shape of input image = ROWS x COLS x CHANNELS \n",
    "                        activation='relu', # activation\n",
    "                        weights=[weight, bias])) # initial weights\n",
    "\n",
    "nb_filters_out, nb_rows, nb_cols, nb_channels, weight, bias = extract_data('conv4_2')    \n",
    "model.add(Convolution2D(nb_filters_out, # number of output filters\n",
    "                        nb_rows,        # number of rows in the input kernel   \n",
    "                        nb_cols,        # number of cols in the input kernel   \n",
    "                        border_mode='same', \n",
    "                        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), # shape of input image = ROWS x COLS x CHANNELS \n",
    "                        activation='relu', # activation\n",
    "                        weights=[weight, bias])) # initial weights\n",
    "\n",
    "nb_filters_out, nb_rows, nb_cols, nb_channels, weight, bias = extract_data('conv4_3')    \n",
    "model.add(Convolution2D(nb_filters_out, # number of output filters\n",
    "                        nb_rows,        # number of rows in the input kernel   \n",
    "                        nb_cols,        # number of cols in the input kernel   \n",
    "                        border_mode='same', \n",
    "                        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), # shape of input image = ROWS x COLS x CHANNELS \n",
    "                        activation='relu', # activation\n",
    "                        weights=[weight, bias])) # initial weights\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='same'))\n",
    "\n",
    "nb_filters_out, nb_rows, nb_cols, nb_channels, weight, bias = extract_data('conv5_1')    \n",
    "model.add(Convolution2D(nb_filters_out, # number of output filters\n",
    "                        nb_rows,        # number of rows in the input kernel   \n",
    "                        nb_cols,        # number of cols in the input kernel   \n",
    "                        border_mode='same', \n",
    "                        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), # shape of input image = ROWS x COLS x CHANNELS \n",
    "                        activation='relu', # activation\n",
    "                        weights=[weight, bias])) # initial weights\n",
    "\n",
    "nb_filters_out, nb_rows, nb_cols, nb_channels, weight, bias = extract_data('conv5_2')    \n",
    "model.add(Convolution2D(nb_filters_out, # number of output filters\n",
    "                        nb_rows,        # number of rows in the input kernel   \n",
    "                        nb_cols,        # number of cols in the input kernel   \n",
    "                        border_mode='same', \n",
    "                        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), # shape of input image = ROWS x COLS x CHANNELS \n",
    "                        activation='relu', # activation\n",
    "                        weights=[weight, bias])) # initial weights\n",
    "\n",
    "nb_filters_out, nb_rows, nb_cols, nb_channels, weight, bias = extract_data('conv5_3')    \n",
    "model.add(Convolution2D(nb_filters_out, # number of output filters\n",
    "                        nb_rows,        # number of rows in the input kernel   \n",
    "                        nb_cols,        # number of cols in the input kernel   \n",
    "                        border_mode='same', \n",
    "                        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), # shape of input image = ROWS x COLS x CHANNELS \n",
    "                        activation='relu', # activation\n",
    "                        weights=[weight, bias])) # initial weights\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, border_mode='same'))\n",
    "\n",
    "\n",
    "\n",
    "# run on a simple image\n",
    "res = model.predict(img, batch_size=1)\n",
    "print res.shape\n",
    "print res\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Comment: perfect match at this point between vgg_keras (this file) with vgg_tf.\n",
    "\n",
    "TODO: \n",
    "1. convert this file into a class as it's done in the following:\n",
    "    https://github.com/fastai/courses/blob/master/deeplearning1/nbs/vgg16.py\n",
    "2. build a class that enable to chop down from 1000 categories to a few  categories as it's done in the link above.\n",
    "3. Train the model on the LSUN db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
