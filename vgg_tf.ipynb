{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement VGG using TF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys in layers =  ['conv5_1', 'fc6', 'conv5_3', 'fc7', 'fc8', 'conv5_2', 'conv4_1', 'conv4_2', 'conv4_3', 'conv3_3', 'conv3_2', 'conv3_1', 'conv1_1', 'conv1_2', 'conv2_2', 'conv2_1'] \n",
      "\n",
      "weights shape in conv1_1 (3, 3, 3, 64) \n",
      "\n",
      "bias shape in conv1_1 (64,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "# load weights from https://dl.dropboxusercontent.com/u/50333326/vgg16.npy\n",
    "path = '/home/ariel/DL/tensorflow/tutorials/'\n",
    "vgg16_npy_path = os.path.join(path, 'vgg16.npy')            \n",
    "data_dict = np.load(vgg16_npy_path, encoding='latin1').item()\n",
    "\n",
    "# print keys in dictionary - \n",
    "# here it prints all the layers names in the VGG net\n",
    "name = 'conv1_1'\n",
    "print 'keys in layers = ', data_dict.keys(), '\\n'\n",
    "# tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "print 'weights shape in conv1_1', data_dict[name][0].shape, '\\n'\n",
    "print 'bias shape in conv1_1', data_dict[name][1].shape, '\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Conv Block in TF**\n",
    "in the _fc2conv() block, each fully connected layer is converted into a convolutional one.\n",
    "For 'fc8', the last fc block you can fine tune a number of classes which is lower than the \n",
    "initial number of classes (=1000). \n",
    "For the moment, the new number of classes == original number of classes == 1000.\n",
    "Two methods may be used in order to  convert the original num of classes to a new num of classes:\n",
    "1. averaging - see https://github.com/MarvinTeichmann/tensorflow-fcn/blob/master/fcn8_vgg.py\n",
    "2. fine tuning - see https://github.com/fastai/courses/blob/master/deeplearning1/nbs/vgg16.py\n",
    "3. \n",
    "\n",
    "both methods must be experimented, the best one must be selected!!!....\n",
    "\n",
    "Another note: I'm not using weight decay - need to experiment with it a bit !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _max_pool(bottom, name):\n",
    "    pool = tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                          padding='SAME', name=name)\n",
    "    return pool\n",
    "\n",
    "def get_weights(name):\n",
    "    init = tf.constant_initializer(value=data_dict[name][0], dtype=tf.float32)\n",
    "    weights = tf.get_variable(name=\"weights\", initializer=init, shape=data_dict[name][0].shape)\n",
    "    return weights\n",
    "\n",
    "def get_biases(name):\n",
    "    init = tf.constant_initializer(value=data_dict[name][1], dtype=tf.float32)\n",
    "    biases = tf.get_variable(name=\"biases\", initializer=init, shape=data_dict[name][1].shape)\n",
    "    return biases\n",
    "\n",
    "# convert FC layer into Convolution layer\n",
    "def _fc2conv(bottom, name, num_classes = None):\n",
    "    with tf.variable_scope(name):# as scope:\n",
    "        weights = data_dict[name][0]\n",
    "        if name == 'fc6':        \n",
    "            shape = [7, 7, 512, 4096] # tf weights: [kernel_rows, kernel_cols, input, output]\n",
    "            weights = weights.reshape(shape)\n",
    "#             print 'fc6', weights.shape\n",
    "        elif name == 'fc7':        \n",
    "            shape = [1, 1, 4096, 4096]\n",
    "            weights = weights.reshape(shape)\n",
    "#             print 'fc7', weights.shape\n",
    "        else: # name == 'fc8'\n",
    "            shape = [1, 1, 4096, 1000]\n",
    "            weights = weights.reshape(shape) # all 1000 classes\n",
    "#             print 'fc8', weights.shape\n",
    "\n",
    "        # set weights\n",
    "        init = tf.constant_initializer(value=weights, dtype=tf.float32)\n",
    "        filt = tf.get_variable(name=\"weights\", initializer=init, shape=shape)\n",
    "\n",
    "        # conv\n",
    "        conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # bias\n",
    "        conv_biases = get_biases(name)\n",
    "        bias = tf.nn.bias_add(conv, conv_biases)\n",
    "\n",
    "        # relu\n",
    "        bias = tf.nn.relu(bias)\n",
    "\n",
    "        # return\n",
    "        return bias\n",
    "\n",
    "def _conv_layer(bottom, name):\n",
    "    with tf.variable_scope(name):# as scope:\n",
    "        # get filter weights\n",
    "        weights = get_weights(name)\n",
    "       \n",
    "        # get filter biases\n",
    "        biases = get_biases(name)\n",
    "\n",
    "        # convolve: weights * bottom\n",
    "        conv = tf.nn.conv2d(bottom, weights, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # add biases: weights * bottom + biases\n",
    "        conv_biases = tf.nn.bias_add(conv, biases)\n",
    "\n",
    "        # relu: relu(weights * bottom + biases)\n",
    "        conv_biases_relu = tf.nn.relu(conv_biases)\n",
    "\n",
    "        return conv_biases_relu\n",
    "    \n",
    "def get_deconv_filter(f_shape):\n",
    "        width = f_shape[0]\n",
    "        heigh = f_shape[0]\n",
    "        f = ceil(width/2.0)\n",
    "        c = (2 * f - 1 - f % 2) / (2.0 * f)\n",
    "        bilinear = np.zeros([f_shape[0], f_shape[1]])\n",
    "        for x in range(width):\n",
    "            for y in range(heigh):\n",
    "                value = (1 - abs(x / f - c)) * (1 - abs(y / f - c))\n",
    "                bilinear[x, y] = value\n",
    "        weights = np.zeros(f_shape)\n",
    "        for i in range(f_shape[2]):\n",
    "            weights[:, :, i, i] = bilinear\n",
    "\n",
    "        init = tf.constant_initializer(value=weights, dtype=tf.float32)\n",
    "        var = tf.get_variable(name=\"up_filter\", initializer=init, shape=weights.shape)\n",
    "        return var\n",
    "\n",
    "# currently - no l2 regularization   \n",
    "def _variable_with_weight_decay(shape, stddev, wd):\n",
    "        \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "        Note that the Variable is initialized with a truncated normal\n",
    "        distribution.\n",
    "        A weight decay is added only if one is specified.\n",
    "        Args:\n",
    "          name: name of the variable\n",
    "          shape: list of ints\n",
    "          stddev: standard deviation of a truncated Gaussian\n",
    "          wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "              decay is not added for this Variable.\n",
    "        Returns:\n",
    "          Variable Tensor\n",
    "        \"\"\"\n",
    "\n",
    "        initializer = tf.truncated_normal_initializer(stddev=stddev)\n",
    "        var = tf.get_variable('weights', shape=shape, initializer=initializer)\n",
    "\n",
    "#         collection_name = tf.GraphKeys.REGULARIZATION_LOSSES\n",
    "#         if wd and (not tf.get_variable_scope().reuse):\n",
    "#             weight_decay = tf.multiply(\n",
    "#                 tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "#             tf.add_to_collection(collection_name, weight_decay)\n",
    "#         _variable_summaries(var)\n",
    "        return var    \n",
    "\n",
    "\n",
    "def _bias_variable(shape, constant=0.0):\n",
    "        initializer = tf.constant_initializer(constant)\n",
    "        var = tf.get_variable(name='biases', shape=shape, initializer=initializer)\n",
    "        \n",
    "        return var\n",
    "\n",
    "def _score_layer(bottom, name, num_classes):\n",
    "        with tf.variable_scope(name):\n",
    "            # get number of input channels\n",
    "            in_features = bottom.get_shape()[3].value\n",
    "            shape = [1, 1, in_features, num_classes]\n",
    "            # He initialization Sheme\n",
    "            if name == \"score_fr\":\n",
    "                num_input = in_features\n",
    "                stddev = (2 / num_input)**0.5\n",
    "            elif name == \"score_pool4\":\n",
    "                stddev = 0.001\n",
    "            elif name == \"score_pool3\":\n",
    "                stddev = 0.0001\n",
    "            # Apply convolution\n",
    "            w_decay = 5e-4#self.wd\n",
    "\n",
    "            weights = _variable_with_weight_decay(shape, stddev, w_decay)\n",
    "            conv = tf.nn.conv2d(bottom, weights, [1, 1, 1, 1], padding='SAME')\n",
    "            # Apply bias\n",
    "            conv_biases = _bias_variable([num_classes], constant=0.0)\n",
    "            bias = tf.nn.bias_add(conv, conv_biases)\n",
    "\n",
    "#             _activation_summary(bias)\n",
    "\n",
    "            return bias    \n",
    "        \n",
    "def _upscore_layer(bottom, shape, num_classes, name, ksize=4, stride=2):\n",
    "        strides = [1, stride, stride, 1]\n",
    "        with tf.variable_scope(name):\n",
    "            in_features = bottom.get_shape()[3].value\n",
    "\n",
    "            if shape is None:\n",
    "                # Compute shape out of Bottom\n",
    "                in_shape = tf.shape(bottom)\n",
    "\n",
    "                h = ((in_shape[1] - 1) * stride) + 1\n",
    "                w = ((in_shape[2] - 1) * stride) + 1\n",
    "                new_shape = [in_shape[0], h, w, num_classes]\n",
    "            else:\n",
    "                new_shape = [shape[0], shape[1], shape[2], num_classes]\n",
    "#             output_shape = tf.stack(new_shape)\n",
    "\n",
    "            f_shape = [ksize, ksize, num_classes, in_features]\n",
    "          \n",
    "            weights = get_deconv_filter(f_shape)\n",
    "            deconv = tf.nn.conv2d_transpose(bottom, weights, new_shape,\n",
    "                                            strides=strides, padding='SAME')\n",
    "\n",
    "        return deconv    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** the network **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 14, 14, 20)\n",
      "[[[[ 2.04171395 -2.56970525 -1.77781034 ...,  0.89347905 -2.68317986\n",
      "    -1.61154878]\n",
      "   [-0.24284291 -1.85051465 -1.00107169 ..., -0.31923321 -2.58583021\n",
      "    -0.92440915]\n",
      "   [-0.09194654 -0.99017757 -0.66342604 ...,  0.1794512  -1.93524683\n",
      "    -0.75973552]\n",
      "   ..., \n",
      "   [-0.0527007  -0.90517104 -0.69214511 ...,  0.17268394 -1.88305366\n",
      "    -0.75407839]\n",
      "   [ 0.1254195  -0.67680436 -0.80938649 ...,  0.38627341 -2.18109536\n",
      "    -1.06300688]\n",
      "   [ 1.67231965 -1.30818033 -2.20197105 ...,  0.55524033 -0.92248863\n",
      "    -1.77833533]]\n",
      "\n",
      "  [[-0.01622808 -0.74701178 -0.81194186 ...,  0.86736315 -1.27415359\n",
      "    -1.35166657]\n",
      "   [-0.6100679   0.19764349 -0.30677283 ...,  0.47503155 -0.73820388\n",
      "    -0.74768996]\n",
      "   [-0.26006109  0.38557193 -0.20660688 ...,  0.31468454 -0.45800251\n",
      "    -0.56117243]\n",
      "   ..., \n",
      "   [-0.39624178  0.451644   -0.17920198 ...,  0.44634181 -0.39602423\n",
      "    -0.50785339]\n",
      "   [-0.58567691  0.52538747 -0.30106038 ...,  0.91013157 -0.27931437\n",
      "    -0.85501492]\n",
      "   [ 0.19287968  0.18801922 -0.88814634 ...,  0.69581723 -0.0538795\n",
      "    -1.44516456]]\n",
      "\n",
      "  [[ 0.02458012 -0.79472661 -0.63968968 ...,  0.9102124  -1.17997193\n",
      "    -0.64449644]\n",
      "   [-0.35872948  0.23209116 -0.1862876  ...,  0.29934371 -0.48100296\n",
      "    -0.48756135]\n",
      "   [-0.25277662  0.32472175 -0.23892389 ...,  0.21591954 -0.34158677\n",
      "    -0.44265908]\n",
      "   ..., \n",
      "   [-0.3236222   0.43213463 -0.1735846  ...,  0.26842794 -0.29804733\n",
      "    -0.31191093]\n",
      "   [-0.52831709  0.46718109 -0.29160947 ...,  0.54477584 -0.36628515\n",
      "    -0.53080994]\n",
      "   [ 0.03140797  0.09168918 -0.64690983 ...,  0.6458708  -0.29118532\n",
      "    -0.85028344]]\n",
      "\n",
      "  ..., \n",
      "  [[-0.06875604 -0.95375496 -0.44091791 ...,  0.91499925 -1.20903921\n",
      "    -0.71249247]\n",
      "   [-0.30450073  0.13535729 -0.07736185 ...,  0.22893846 -0.41968361\n",
      "    -0.49518472]\n",
      "   [-0.29507527  0.2473205  -0.10728303 ...,  0.17952684 -0.31232199\n",
      "    -0.4974165 ]\n",
      "   ..., \n",
      "   [-0.36043409  0.27648911 -0.2012147  ...,  0.22349954 -0.31630617\n",
      "    -0.41379032]\n",
      "   [-0.52682501  0.32612726 -0.33406854 ...,  0.46770614 -0.3762939\n",
      "    -0.6240077 ]\n",
      "   [-0.08252044 -0.09923284 -0.64505792 ...,  0.6690312  -0.32945734\n",
      "    -0.85029113]]\n",
      "\n",
      "  [[ 0.17618155 -0.60817456 -0.8610456  ...,  0.83704007 -1.61852753\n",
      "    -1.22628522]\n",
      "   [ 0.02167333  0.1071956  -0.39998066 ...,  0.08905853 -0.66092813\n",
      "    -0.75938028]\n",
      "   [-0.05604845  0.20451076 -0.29097214 ...,  0.07159291 -0.4620479\n",
      "    -0.70323604]\n",
      "   ..., \n",
      "   [-0.12173814  0.196061   -0.41440809 ...,  0.09992535 -0.50830543\n",
      "    -0.69567484]\n",
      "   [-0.31561404  0.51494688 -0.56650418 ...,  0.35714227 -0.35994911\n",
      "    -0.87103075]\n",
      "   [ 0.15719312 -0.03847038 -1.3072201  ...,  0.86739904 -0.26260346\n",
      "    -1.25963342]]\n",
      "\n",
      "  [[ 3.36268878 -1.34192026 -2.05624676 ...,  0.0111973  -2.65428233\n",
      "    -3.13142586]\n",
      "   [ 0.96706963 -1.14837873 -0.10667971 ..., -0.57193065 -2.5848248\n",
      "    -2.1032989 ]\n",
      "   [ 0.58840299 -0.59752816 -0.2001497  ..., -0.13097543 -2.13252401\n",
      "    -2.18217826]\n",
      "   ..., \n",
      "   [ 0.58305633 -0.65566432 -0.41638017 ..., -0.04816278 -1.98684859\n",
      "    -2.15608215]\n",
      "   [ 0.7722432  -0.53146702 -0.35326838 ..., -0.19318068 -1.92400348\n",
      "    -2.76106143]\n",
      "   [ 3.01227665 -1.3687923  -2.78990817 ...,  0.26129162 -2.43877459\n",
      "    -3.8277843 ]]]]\n"
     ]
    }
   ],
   "source": [
    "# this command clean all nodes in the graph + variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# load an image\n",
    "IMAGE_SIZE = 224\n",
    "img_shape = (1, IMAGE_SIZE, IMAGE_SIZE, 3) # tf format (N,H,W,C)\n",
    "img = np.linspace(-0.1, 0.5, num=np.prod(img_shape)).reshape(img_shape)\n",
    "\n",
    "# remove the mean of imagenet\n",
    "vgg_mean = np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape((1,1,3)) # BGR\n",
    "img = img - vgg_mean\n",
    "\n",
    "# tf handle to img\n",
    "tf_img = tf.Variable(img, name=\"img\", dtype=tf.float32)\n",
    "\n",
    "# VGG8 network\n",
    "\n",
    "_conv1_1 = _conv_layer(tf_img, 'conv1_1')\n",
    "_conv1_2 = _conv_layer(_conv1_1, 'conv1_2')\n",
    "_pool1   = _max_pool(_conv1_2, 'pool1')\n",
    "\n",
    "_conv2_1 = _conv_layer(_pool1, 'conv2_1')\n",
    "_conv2_2 = _conv_layer(_conv2_1, 'conv2_2')\n",
    "_pool2   = _max_pool(_conv2_2, 'pool2')\n",
    "\n",
    "_conv3_1 = _conv_layer(_pool2, 'conv3_1')\n",
    "_conv3_2 = _conv_layer(_conv3_1, 'conv3_2')\n",
    "_conv3_3 = _conv_layer(_conv3_2, 'conv3_3')\n",
    "_pool3   = _max_pool(_conv3_3, 'pool3')\n",
    "\n",
    "_conv4_1 = _conv_layer(_pool3, 'conv4_1')\n",
    "_conv4_2 = _conv_layer(_conv4_1, 'conv4_2')\n",
    "_conv4_3 = _conv_layer(_conv4_2, 'conv4_3')\n",
    "_pool4   = _max_pool(_conv4_3, 'pool4')\n",
    "\n",
    "_conv5_1 = _conv_layer(_pool4, 'conv5_1')\n",
    "_conv5_2 = _conv_layer(_conv5_1, 'conv5_2')\n",
    "_conv5_3 = _conv_layer(_conv5_2, 'conv5_3')\n",
    "_pool5   = _max_pool(_conv5_3, 'pool5')\n",
    "\n",
    "_fc6 = _fc2conv(_pool5, 'fc6')\n",
    "_fc7 = _fc2conv(_fc6, 'fc7')\n",
    "_fc8 = _fc2conv(_fc7, 'fc8')\n",
    "\n",
    "_upscore2 = _upscore_layer(_fc8, \n",
    "                           tf.shape(_pool4), \n",
    "                           num_classes = 20, \n",
    "                           name = 'upscore2')\n",
    "\n",
    "_score_pool4 = _score_layer(_pool4, \n",
    "                            name = 'score_pool4', \n",
    "                            num_classes=20)\n",
    "\n",
    "_fuse_pool4 = tf.add(_upscore2, _score_pool4)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "res = sess.run(_fuse_pool4) \n",
    "print res.shape\n",
    "print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
