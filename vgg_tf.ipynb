{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement VGG using TF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys in layers =  ['conv5_1', 'fc6', 'conv5_3', 'fc7', 'fc8', 'conv5_2', 'conv4_1', 'conv4_2', 'conv4_3', 'conv3_3', 'conv3_2', 'conv3_1', 'conv1_1', 'conv1_2', 'conv2_2', 'conv2_1'] \n",
      "\n",
      "weights shape in conv1_1 (3, 3, 3, 64) \n",
      "\n",
      "bias shape in conv1_1 (64,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# load weights from https://dl.dropboxusercontent.com/u/50333326/vgg16.npy\n",
    "path = '/home/ariel/DL/tensorflow/tutorials/'\n",
    "vgg16_npy_path = os.path.join(path, 'vgg16.npy')            \n",
    "data_dict = np.load(vgg16_npy_path, encoding='latin1').item()\n",
    "\n",
    "# print keys in dictionary - \n",
    "# here it prints all the layers names in the VGG net\n",
    "name = 'conv1_1'\n",
    "print 'keys in layers = ', data_dict.keys(), '\\n'\n",
    "# tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "print 'weights shape in conv1_1', data_dict[name][0].shape, '\\n'\n",
    "print 'bias shape in conv1_1', data_dict[name][1].shape, '\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Conv Block in TF**\n",
    "in the _fc2conv() block, each fully connected layer is converted into a convolutional one.\n",
    "For 'fc8', the last fc block you can fine tune a number of classes which is lower than the \n",
    "initial number of classes (=1000). \n",
    "For the moment, the new number of classes == original number of classes == 1000.\n",
    "Two methods may be used in order to  convert the original num of classes to a new num of clases:\n",
    "1. averaging - see https://github.com/MarvinTeichmann/tensorflow-fcn/blob/master/fcn8_vgg.py\n",
    "2. fine tuning - see https://github.com/fastai/courses/blob/master/deeplearning1/nbs/vgg16.py\n",
    "\n",
    "both methods must be experimented, the best one must be slected!!!...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _max_pool(bottom, name):\n",
    "    pool = tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                          padding='SAME', name=name)\n",
    "    return pool\n",
    "\n",
    "def get_weights(name):\n",
    "    init = tf.constant_initializer(value=data_dict[name][0], dtype=tf.float32)\n",
    "    weights = tf.get_variable(name=\"weights\", initializer=init, shape=data_dict[name][0].shape)\n",
    "    return weights\n",
    "\n",
    "def get_biases(name):\n",
    "    init = tf.constant_initializer(value=data_dict[name][1], dtype=tf.float32)\n",
    "    biases = tf.get_variable(name=\"biases\", initializer=init, shape=data_dict[name][1].shape)\n",
    "    return biases\n",
    "\n",
    "# convert FC layer into Convolution layer\n",
    "def _fc2conv(bottom, name, num_classes = None):\n",
    "    with tf.variable_scope(name):# as scope:\n",
    "        weights = data_dict[name][0]\n",
    "        if name == 'fc6':        \n",
    "            shape = [7, 7, 512, 4096] # tf weights: [kernel_rows, kernel_cols, input, output]\n",
    "            weights = weights.reshape(shape)\n",
    "            print 'fc6', weights.shape\n",
    "        elif name == 'fc7':        \n",
    "            shape = [1, 1, 4096, 4096]\n",
    "            weights = weights.reshape(shape)\n",
    "            print 'fc7', weights.shape\n",
    "        else: # name == 'fc8'\n",
    "            shape = [1, 1, 4096, 1000]\n",
    "            weights = weights.reshape(shape) # all 1000 classes\n",
    "            print 'fc8', weights.shape\n",
    "\n",
    "        # set weights\n",
    "        init = tf.constant_initializer(value=weights, dtype=tf.float32)\n",
    "        filt = tf.get_variable(name=\"weights\", initializer=init, shape=shape)\n",
    "\n",
    "        # conv\n",
    "        conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # bias\n",
    "        conv_biases = get_biases(name)\n",
    "        bias = tf.nn.bias_add(conv, conv_biases)\n",
    "\n",
    "        # relu\n",
    "        bias = tf.nn.relu(bias)\n",
    "\n",
    "        # return\n",
    "        return bias\n",
    "\n",
    "def _conv_layer(bottom, name):\n",
    "    with tf.variable_scope(name):# as scope:\n",
    "        # get filter weights\n",
    "        weights = get_weights(name)\n",
    "       \n",
    "        # get filter biases\n",
    "        biases = get_biases(name)\n",
    "\n",
    "        # convolve: weights * bottom\n",
    "        conv = tf.nn.conv2d(bottom, weights, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # add biases: weights * bottom + biases\n",
    "        conv_biases = tf.nn.bias_add(conv, biases)\n",
    "\n",
    "        # relu: relu(weights * bottom + biases)\n",
    "        conv_biases_relu = tf.nn.relu(conv_biases)\n",
    "\n",
    "        return conv_biases_relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** the network **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc6 (7, 7, 512, 4096)\n",
      "fc7 (1, 1, 4096, 4096)\n",
      "fc8 (1, 1, 4096, 1000)\n",
      "(1, 7, 7, 1000)\n",
      "[[[[ 0.          0.09025753  0.         ...,  0.          0.          0.79901946]\n",
      "   [ 0.          0.07668401  0.         ...,  0.          0.          0.86026871]\n",
      "   [ 0.          0.07620315  0.         ...,  0.          0.          0.80350524]\n",
      "   ..., \n",
      "   [ 0.          0.1233471   0.         ...,  0.          0.          0.86561912]\n",
      "   [ 0.          0.14276227  0.         ...,  0.          0.          0.98144484]\n",
      "   [ 0.          0.01396307  0.         ...,  0.          0.          1.06213295]]\n",
      "\n",
      "  [[ 0.          0.10429658  0.         ...,  0.          0.          0.76482892]\n",
      "   [ 0.          0.15433228  0.         ...,  0.          0.          0.8034817 ]\n",
      "   [ 0.          0.20993349  0.         ...,  0.          0.          0.61662412]\n",
      "   ..., \n",
      "   [ 0.          0.2102727   0.         ...,  0.          0.          0.81622267]\n",
      "   [ 0.          0.27374965  0.         ...,  0.          0.          0.87952626]\n",
      "   [ 0.          0.21046048  0.         ...,  0.          0.          0.92164785]]\n",
      "\n",
      "  [[ 0.          0.32233211  0.06482287 ...,  0.          0.          0.73647219]\n",
      "   [ 0.          0.42404172  0.01331848 ...,  0.          0.          0.88839006]\n",
      "   [ 0.          0.42058632  0.02248825 ...,  0.          0.          0.65484107]\n",
      "   ..., \n",
      "   [ 0.          0.44775113  0.         ...,  0.          0.          0.8304801 ]\n",
      "   [ 0.          0.47989723  0.         ...,  0.          0.          0.86970389]\n",
      "   [ 0.          0.39042416  0.         ...,  0.          0.          1.05478978]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.          0.          0.27149794 ...,  0.          0.          0.6088149 ]\n",
      "   [ 0.          0.          0.21473713 ...,  0.          0.          0.63496709]\n",
      "   [ 0.          0.          0.16551852 ...,  0.          0.          0.46089008]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.62094599]\n",
      "   [ 0.          0.          0.11057194 ...,  0.          0.          0.67146516]\n",
      "   [ 0.          0.          0.09799137 ...,  0.          0.          0.82930595]]\n",
      "\n",
      "  [[ 0.          0.01017243  0.14518969 ...,  0.          0.          0.84099281]\n",
      "   [ 0.          0.          0.20195542 ...,  0.          0.          0.83552372]\n",
      "   [ 0.          0.          0.23354939 ...,  0.          0.          0.68829626]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.83138216]\n",
      "   [ 0.          0.05696653  0.1221808  ...,  0.          0.          0.91089356]\n",
      "   [ 0.          0.          0.10588226 ...,  0.          0.          1.01862943]]\n",
      "\n",
      "  [[ 0.          0.17442387  0.269732   ...,  0.          0.          0.70219249]\n",
      "   [ 0.          0.19289199  0.30043557 ...,  0.          0.          0.64436978]\n",
      "   [ 0.          0.02514791  0.28535727 ...,  0.          0.          0.48902807]\n",
      "   ..., \n",
      "   [ 0.          0.02454753  0.03905445 ...,  0.          0.          0.68870151]\n",
      "   [ 0.          0.15457436  0.11827637 ...,  0.          0.          0.74157888]\n",
      "   [ 0.          0.10902363  0.08206049 ...,  0.          0.          0.91486251]]]]\n"
     ]
    }
   ],
   "source": [
    "# this command clean all nodes in the graph + variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# load an image\n",
    "IMAGE_SIZE = 224\n",
    "img_shape = (1, IMAGE_SIZE, IMAGE_SIZE, 3) # tf format (N,H,W,C)\n",
    "img = np.linspace(-0.1, 0.5, num=np.prod(img_shape)).reshape(img_shape)\n",
    "\n",
    "# remove the mean of imagenet\n",
    "vgg_mean = np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape((1,1,3)) # BGR\n",
    "img = img - vgg_mean\n",
    "\n",
    "# tf handle to img\n",
    "tf_img = tf.Variable(img, name=\"img\", dtype=tf.float32)\n",
    "\n",
    "\n",
    "_conv1_1 = _conv_layer(tf_img, 'conv1_1')\n",
    "_conv1_2 = _conv_layer(_conv1_1, 'conv1_2')\n",
    "_pool1   = _max_pool(_conv1_2, 'pool1')\n",
    "\n",
    "_conv2_1 = _conv_layer(_pool1, 'conv2_1')\n",
    "_conv2_2 = _conv_layer(_conv2_1, 'conv2_2')\n",
    "_pool2   = _max_pool(_conv2_2, 'pool2')\n",
    "\n",
    "_conv3_1 = _conv_layer(_pool2, 'conv3_1')\n",
    "_conv3_2 = _conv_layer(_conv3_1, 'conv3_2')\n",
    "_conv3_3 = _conv_layer(_conv3_2, 'conv3_3')\n",
    "_pool3   = _max_pool(_conv3_3, 'pool3')\n",
    "\n",
    "_conv4_1 = _conv_layer(_pool3, 'conv4_1')\n",
    "_conv4_2 = _conv_layer(_conv4_1, 'conv4_2')\n",
    "_conv4_3 = _conv_layer(_conv4_2, 'conv4_3')\n",
    "_pool4   = _max_pool(_conv4_3, 'pool4')\n",
    "\n",
    "_conv5_1 = _conv_layer(_pool4, 'conv5_1')\n",
    "_conv5_2 = _conv_layer(_conv5_1, 'conv5_2')\n",
    "_conv5_3 = _conv_layer(_conv5_2, 'conv5_3')\n",
    "_pool5   = _max_pool(_conv5_3, 'pool5')\n",
    "\n",
    "_fc6 = _fc2conv(_pool5, 'fc6')\n",
    "_fc7 = _fc2conv(_fc6, 'fc7')\n",
    "_fc8 = _fc2conv(_fc7, 'fc8')\n",
    "\n",
    "# weights = data_dict['fc6'][0]\n",
    "# weights = weights.reshape([7, 7, 512, 4096])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "res = sess.run(_fc8) \n",
    "print res.shape\n",
    "print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
