{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement VGG using TF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys in layers =  ['conv5_1', 'fc6', 'conv5_3', 'fc7', 'fc8', 'conv5_2', 'conv4_1', 'conv4_2', 'conv4_3', 'conv3_3', 'conv3_2', 'conv3_1', 'conv1_1', 'conv1_2', 'conv2_2', 'conv2_1'] \n",
      "\n",
      "weights shape in conv1_1 (3, 3, 3, 64) \n",
      "\n",
      "bias shape in conv1_1 (64,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "# load weights from https://dl.dropboxusercontent.com/u/50333326/vgg16.npy\n",
    "path = '/home/ariel/DL/tensorflow/tutorials/'\n",
    "vgg16_npy_path = os.path.join(path, 'vgg16.npy')            \n",
    "data_dict = np.load(vgg16_npy_path, encoding='latin1').item()\n",
    "\n",
    "# print keys in dictionary - \n",
    "# here it prints all the layers names in the VGG net\n",
    "name = 'conv1_1'\n",
    "print 'keys in layers = ', data_dict.keys(), '\\n'\n",
    "# tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "print 'weights shape in conv1_1', data_dict[name][0].shape, '\\n'\n",
    "print 'bias shape in conv1_1', data_dict[name][1].shape, '\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Conv Block in TF**\n",
    "in the _fc2conv() block, each fully connected layer is converted into a convolutional one.\n",
    "For 'fc8', the last fc block you can fine tune a number of classes which is lower than the \n",
    "initial number of classes (=1000). \n",
    "For the moment, the new number of classes == original number of classes == 1000.\n",
    "Two methods may be used in order to  convert the original num of classes to a new num of classes:\n",
    "1. averaging - see https://github.com/MarvinTeichmann/tensorflow-fcn/blob/master/fcn8_vgg.py\n",
    "2. fine tuning - see https://github.com/fastai/courses/blob/master/deeplearning1/nbs/vgg16.py\n",
    "3. \n",
    "\n",
    "both methods must be experimented, the best one must be selected!!!....\n",
    "\n",
    "Another note: I'm not using weight decay - need to experiment with it a bit !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _max_pool(bottom, name):\n",
    "    pool = tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                          padding='SAME', name=name)\n",
    "    return pool\n",
    "\n",
    "def get_weights(name):\n",
    "    init = tf.constant_initializer(value=data_dict[name][0], dtype=tf.float32)\n",
    "    weights = tf.get_variable(name=\"weights\", initializer=init, shape=data_dict[name][0].shape)\n",
    "    return weights\n",
    "\n",
    "def get_biases(name):\n",
    "    init = tf.constant_initializer(value=data_dict[name][1], dtype=tf.float32)\n",
    "    biases = tf.get_variable(name=\"biases\", initializer=init, shape=data_dict[name][1].shape)\n",
    "    return biases\n",
    "\n",
    "# convert FC layer into Convolution layer\n",
    "def _fc2conv(bottom, name, num_classes = None):\n",
    "    with tf.variable_scope(name):# as scope:\n",
    "        weights = data_dict[name][0]\n",
    "        if name == 'fc6':        \n",
    "            shape = [7, 7, 512, 4096] # tf weights: [kernel_rows, kernel_cols, input, output]\n",
    "            weights = weights.reshape(shape)\n",
    "#             print 'fc6', weights.shape\n",
    "        elif name == 'fc7':        \n",
    "            shape = [1, 1, 4096, 4096]\n",
    "            weights = weights.reshape(shape)\n",
    "#             print 'fc7', weights.shape\n",
    "        else: # name == 'fc8'\n",
    "            shape = [1, 1, 4096, 1000]\n",
    "            weights = weights.reshape(shape) # all 1000 classes\n",
    "#             print 'fc8', weights.shape\n",
    "\n",
    "        # set weights\n",
    "        init = tf.constant_initializer(value=weights, dtype=tf.float32)\n",
    "        filt = tf.get_variable(name=\"weights\", initializer=init, shape=shape)\n",
    "\n",
    "        # conv\n",
    "        conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # bias\n",
    "        conv_biases = get_biases(name)\n",
    "        bias = tf.nn.bias_add(conv, conv_biases)\n",
    "\n",
    "        # relu\n",
    "        bias = tf.nn.relu(bias)\n",
    "\n",
    "        # return\n",
    "        return bias\n",
    "\n",
    "def _conv_layer(bottom, name):\n",
    "    with tf.variable_scope(name):# as scope:\n",
    "        # get filter weights\n",
    "        weights = get_weights(name)\n",
    "       \n",
    "        # get filter biases\n",
    "        biases = get_biases(name)\n",
    "\n",
    "        # convolve: weights * bottom\n",
    "        conv = tf.nn.conv2d(bottom, weights, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # add biases: weights * bottom + biases\n",
    "        conv_biases = tf.nn.bias_add(conv, biases)\n",
    "\n",
    "        # relu: relu(weights * bottom + biases)\n",
    "        conv_biases_relu = tf.nn.relu(conv_biases)\n",
    "\n",
    "        return conv_biases_relu\n",
    "    \n",
    "def get_deconv_filter(f_shape):\n",
    "        width = f_shape[0]\n",
    "        heigh = f_shape[0]\n",
    "        f = ceil(width/2.0)\n",
    "        c = (2 * f - 1 - f % 2) / (2.0 * f)\n",
    "        bilinear = np.zeros([f_shape[0], f_shape[1]])\n",
    "        for x in range(width):\n",
    "            for y in range(heigh):\n",
    "                value = (1 - abs(x / f - c)) * (1 - abs(y / f - c))\n",
    "                bilinear[x, y] = value\n",
    "        weights = np.zeros(f_shape)\n",
    "        for i in range(f_shape[2]):\n",
    "            weights[:, :, i, i] = bilinear\n",
    "\n",
    "        init = tf.constant_initializer(value=weights, dtype=tf.float32)\n",
    "        var = tf.get_variable(name=\"up_filter\", initializer=init, shape=weights.shape)\n",
    "        return var\n",
    "\n",
    "# currently - no l2 regularization   \n",
    "def _variable_with_weight_decay(shape, stddev, wd):\n",
    "        \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "        Note that the Variable is initialized with a truncated normal\n",
    "        distribution.\n",
    "        A weight decay is added only if one is specified.\n",
    "        Args:\n",
    "          name: name of the variable\n",
    "          shape: list of ints\n",
    "          stddev: standard deviation of a truncated Gaussian\n",
    "          wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "              decay is not added for this Variable.\n",
    "        Returns:\n",
    "          Variable Tensor\n",
    "        \"\"\"\n",
    "\n",
    "        initializer = tf.truncated_normal_initializer(stddev=stddev)\n",
    "        var = tf.get_variable('weights', shape=shape, initializer=initializer)\n",
    "\n",
    "#         collection_name = tf.GraphKeys.REGULARIZATION_LOSSES\n",
    "#         if wd and (not tf.get_variable_scope().reuse):\n",
    "#             weight_decay = tf.multiply(\n",
    "#                 tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "#             tf.add_to_collection(collection_name, weight_decay)\n",
    "#         _variable_summaries(var)\n",
    "        return var    \n",
    "\n",
    "\n",
    "def _bias_variable(shape, constant=0.0):\n",
    "        initializer = tf.constant_initializer(constant)\n",
    "        var = tf.get_variable(name='biases', shape=shape, initializer=initializer)\n",
    "        \n",
    "        return var\n",
    "\n",
    "def _score_layer(bottom, name, num_classes):\n",
    "        with tf.variable_scope(name):\n",
    "            # get number of input channels\n",
    "            in_features = bottom.get_shape()[3].value\n",
    "            shape = [1, 1, in_features, num_classes]\n",
    "            # He initialization Sheme\n",
    "            if name == \"score_fr\":\n",
    "                num_input = in_features\n",
    "                stddev = (2 / num_input)**0.5\n",
    "            elif name == \"score_pool4\":\n",
    "                stddev = 0.001\n",
    "            elif name == \"score_pool3\":\n",
    "                stddev = 0.0001\n",
    "            # Apply convolution\n",
    "            w_decay = 5e-4#self.wd\n",
    "\n",
    "            weights = _variable_with_weight_decay(shape, stddev, w_decay)\n",
    "            conv = tf.nn.conv2d(bottom, weights, [1, 1, 1, 1], padding='SAME')\n",
    "            # Apply bias\n",
    "            conv_biases = _bias_variable([num_classes], constant=0.0)\n",
    "            bias = tf.nn.bias_add(conv, conv_biases)\n",
    "\n",
    "#             _activation_summary(bias)\n",
    "\n",
    "            return bias    \n",
    "        \n",
    "def _upscore_layer(bottom, shape, num_classes, name, ksize=4, stride=2):\n",
    "        strides = [1, stride, stride, 1]\n",
    "        with tf.variable_scope(name):\n",
    "            in_features = bottom.get_shape()[3].value\n",
    "\n",
    "            if shape is None:\n",
    "                # Compute shape out of Bottom\n",
    "                in_shape = tf.shape(bottom)\n",
    "\n",
    "                h = ((in_shape[1] - 1) * stride) + 1\n",
    "                w = ((in_shape[2] - 1) * stride) + 1\n",
    "                new_shape = [in_shape[0], h, w, num_classes]\n",
    "            else:\n",
    "                new_shape = [shape[0], shape[1], shape[2], num_classes]\n",
    "#             output_shape = tf.stack(new_shape)\n",
    "\n",
    "            f_shape = [ksize, ksize, num_classes, in_features]\n",
    "          \n",
    "            weights = get_deconv_filter(f_shape)\n",
    "            deconv = tf.nn.conv2d_transpose(bottom, weights, new_shape, strides=strides, padding='SAME')\n",
    "\n",
    "        return deconv    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** the network **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7, 7, 1000)\n",
      "[[[[ 0.          0.09025753  0.         ...,  0.          0.          0.79901946]\n",
      "   [ 0.          0.07668401  0.         ...,  0.          0.          0.86026871]\n",
      "   [ 0.          0.07620315  0.         ...,  0.          0.          0.80350524]\n",
      "   ..., \n",
      "   [ 0.          0.1233471   0.         ...,  0.          0.          0.86561912]\n",
      "   [ 0.          0.14276227  0.         ...,  0.          0.          0.98144484]\n",
      "   [ 0.          0.01396307  0.         ...,  0.          0.          1.06213295]]\n",
      "\n",
      "  [[ 0.          0.10429658  0.         ...,  0.          0.          0.76482892]\n",
      "   [ 0.          0.15433228  0.         ...,  0.          0.          0.8034817 ]\n",
      "   [ 0.          0.20993349  0.         ...,  0.          0.          0.61662412]\n",
      "   ..., \n",
      "   [ 0.          0.2102727   0.         ...,  0.          0.          0.81622267]\n",
      "   [ 0.          0.27374965  0.         ...,  0.          0.          0.87952626]\n",
      "   [ 0.          0.21046048  0.         ...,  0.          0.          0.92164785]]\n",
      "\n",
      "  [[ 0.          0.32233211  0.06482287 ...,  0.          0.          0.73647219]\n",
      "   [ 0.          0.42404172  0.01331848 ...,  0.          0.          0.88839006]\n",
      "   [ 0.          0.42058632  0.02248825 ...,  0.          0.          0.65484107]\n",
      "   ..., \n",
      "   [ 0.          0.44775113  0.         ...,  0.          0.          0.8304801 ]\n",
      "   [ 0.          0.47989723  0.         ...,  0.          0.          0.86970389]\n",
      "   [ 0.          0.39042416  0.         ...,  0.          0.          1.05478978]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.          0.          0.27149794 ...,  0.          0.          0.6088149 ]\n",
      "   [ 0.          0.          0.21473713 ...,  0.          0.          0.63496709]\n",
      "   [ 0.          0.          0.16551852 ...,  0.          0.          0.46089008]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.62094599]\n",
      "   [ 0.          0.          0.11057194 ...,  0.          0.          0.67146516]\n",
      "   [ 0.          0.          0.09799137 ...,  0.          0.          0.82930595]]\n",
      "\n",
      "  [[ 0.          0.01017243  0.14518969 ...,  0.          0.          0.84099281]\n",
      "   [ 0.          0.          0.20195542 ...,  0.          0.          0.83552372]\n",
      "   [ 0.          0.          0.23354939 ...,  0.          0.          0.68829626]\n",
      "   ..., \n",
      "   [ 0.          0.          0.         ...,  0.          0.          0.83138216]\n",
      "   [ 0.          0.05696653  0.1221808  ...,  0.          0.          0.91089356]\n",
      "   [ 0.          0.          0.10588226 ...,  0.          0.          1.01862943]]\n",
      "\n",
      "  [[ 0.          0.17442387  0.269732   ...,  0.          0.          0.70219249]\n",
      "   [ 0.          0.19289199  0.30043557 ...,  0.          0.          0.64436978]\n",
      "   [ 0.          0.02514791  0.28535727 ...,  0.          0.          0.48902807]\n",
      "   ..., \n",
      "   [ 0.          0.02454753  0.03905445 ...,  0.          0.          0.68870151]\n",
      "   [ 0.          0.15457436  0.11827637 ...,  0.          0.          0.74157888]\n",
      "   [ 0.          0.10902363  0.08206049 ...,  0.          0.          0.91486251]]]]\n"
     ]
    }
   ],
   "source": [
    "# this command clean all nodes in the graph + variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# load an image\n",
    "IMAGE_SIZE = 224\n",
    "img_shape = (1, IMAGE_SIZE, IMAGE_SIZE, 3) # tf format (N,H,W,C)\n",
    "img = np.linspace(-0.1, 0.5, num=np.prod(img_shape)).reshape(img_shape)\n",
    "\n",
    "# remove the mean of imagenet\n",
    "vgg_mean = np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape((1,1,3)) # BGR\n",
    "img = img - vgg_mean\n",
    "\n",
    "# tf handle to img\n",
    "tf_img = tf.Variable(img, name=\"img\", dtype=tf.float32)\n",
    "\n",
    "# VGG8 network\n",
    "\n",
    "_conv1_1 = _conv_layer(tf_img, 'conv1_1')\n",
    "_conv1_2 = _conv_layer(_conv1_1, 'conv1_2')\n",
    "_pool1   = _max_pool(_conv1_2, 'pool1')\n",
    "\n",
    "_conv2_1 = _conv_layer(_pool1, 'conv2_1')\n",
    "_conv2_2 = _conv_layer(_conv2_1, 'conv2_2')\n",
    "_pool2   = _max_pool(_conv2_2, 'pool2')\n",
    "\n",
    "_conv3_1 = _conv_layer(_pool2, 'conv3_1')\n",
    "_conv3_2 = _conv_layer(_conv3_1, 'conv3_2')\n",
    "_conv3_3 = _conv_layer(_conv3_2, 'conv3_3')\n",
    "_pool3   = _max_pool(_conv3_3, 'pool3')\n",
    "\n",
    "_conv4_1 = _conv_layer(_pool3, 'conv4_1')\n",
    "_conv4_2 = _conv_layer(_conv4_1, 'conv4_2')\n",
    "_conv4_3 = _conv_layer(_conv4_2, 'conv4_3')\n",
    "_pool4   = _max_pool(_conv4_3, 'pool4')\n",
    "\n",
    "_conv5_1 = _conv_layer(_pool4, 'conv5_1')\n",
    "_conv5_2 = _conv_layer(_conv5_1, 'conv5_2')\n",
    "_conv5_3 = _conv_layer(_conv5_2, 'conv5_3')\n",
    "_pool5   = _max_pool(_conv5_3, 'pool5')\n",
    "\n",
    "_fc6 = _fc2conv(_pool5, 'fc6')\n",
    "_fc7 = _fc2conv(_fc6, 'fc7')\n",
    "_fc8 = _fc2conv(_fc7, 'fc8')\n",
    "\n",
    "# _upscore2 = _upscore_layer(_fc8, \n",
    "#                            tf.shape(_pool4), \n",
    "#                            num_classes = 20, \n",
    "#                            name = 'upscore2')\n",
    "\n",
    "# _score_pool4 = _score_layer(_pool4, \n",
    "#                             name = 'score_pool4', \n",
    "#                             num_classes=20)\n",
    "\n",
    "# _fuse_pool4 = tf.add(_upscore2, _score_pool4)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "res = sess.run(_fc8) \n",
    "print res.shape\n",
    "print res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
